{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of Offset\n",
    "In this notebook we want to assess the impact of varying each of the offsets, to work out which ones contribute most highly to increased error in the case of miscalibration. The miscalibration will be added to the **raw PV value**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_lcls\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from lume_model.torch import LUMEModule\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from torch.nn import MSELoss\n",
    "from botorch.models.transforms.input import InputTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/pv_info.json', 'r') as f:\n",
    "    pv_info = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "pv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = load_lcls('configs/lcls_variables.yml', 'configs/normalization.json', 'torch_model.pt')\n",
    "output_transformer = deepcopy(nn_model.output_transformers[0])\n",
    "input_transformer = deepcopy(nn_model._input_transformers[0])\n",
    "# we remove the output transformation so we can make comparisons between the outcomes using MSE\n",
    "nn_model._output_transformers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(np.load('data/x_raw_small.npy', allow_pickle=True).astype('float64'))\n",
    "y_test = torch.from_numpy(np.load('data/y_raw_small.npy', allow_pickle=True).astype('float64'))\n",
    "y_test = output_transformer(y_test)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions = torch.tensor([pv_info['pv_to_sim_factor'][pv_info['sim_name_to_pv_name'][feature_name]] for feature_name in nn_model.features])\n",
    "\n",
    "class PVtoSimFactor(InputTransform, torch.nn.Module):\n",
    "    def __init__(self, conversion: torch.Tensor) -> None:\n",
    "        super().__init__()\n",
    "        self._conversion = conversion\n",
    "        self.transform_on_train = True\n",
    "        self.transform_on_eval = True\n",
    "        self.transform_on_fantasize = False\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x * self._conversion\n",
    "\n",
    "    def untransform(self, x):\n",
    "        return x / self._conversion\n",
    "    \n",
    "pv_to_sim = PVtoSimFactor(conversions)\n",
    "x_test_pv = pv_to_sim.untransform(x_test)\n",
    "x_test_transformed = pv_to_sim.transform(x_test_pv)\n",
    "\n",
    "# verify that the transformations work as expected\n",
    "print(x_test)\n",
    "print(x_test_pv)\n",
    "print(x_test_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model._input_transformers.insert(0, pv_to_sim)\n",
    "print(nn_model.input_transformers)\n",
    "base_model = LUMEModule(nn_model, nn_model.features, nn_model.outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOr each input, we will add a certain degree of miscalibration offset (only offset, no scale to begin with) and study the result on the model's prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_degrees = torch.linspace(-0.1, 0.1, 9)  # vary from -10% of mean to +10% of mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = [feature_name for feature_name, var in nn_model.input_variables.items() if var.value_range[0] == var.value_range[1]]\n",
    "print(constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = MSELoss()\n",
    "\n",
    "fig, ax = plt.subplots(2,1, sharex='all', figsize=(12,8))\n",
    "\n",
    "fig2, ax2 = plt.subplots(4,4, figsize=(12,10))\n",
    "ax2 = ax2.ravel()\n",
    "\n",
    "for i, feature_name in enumerate(nn_model.features):\n",
    "    errors = []\n",
    "    offset_tensor = torch.zeros_like(x_test)\n",
    "    for offset_degree in offset_degrees:\n",
    "        # add the offset to the individual input data\n",
    "        offset_value = x_test_pv[:,i].mean() * offset_degree\n",
    "        offset_tensor[:,i] = offset_value\n",
    "        x_test_offset_input = x_test_pv + offset_tensor\n",
    "        \n",
    "        if offset_degree in [-0.1, 0, 0.1]:\n",
    "            ax2[i].hist(x_test_offset_input[:,i], bins=20, label=f'{offset_degree:.2f}', alpha=0.75)\n",
    "\n",
    "        # pass the input through the model and compare with what the result should be\n",
    "        true_result = base_model(x_test_pv)\n",
    "        offset_result = base_model(x_test_offset_input)\n",
    "\n",
    "        mse = mse_loss(true_result, offset_result)\n",
    "        errors.append(mse.item())\n",
    "    if feature_name in constants:\n",
    "        linestyle= 'dashed'\n",
    "        print(feature_name, errors)\n",
    "        ax[0].plot(offset_degrees, errors, linestyle=linestyle, label=feature_name)\n",
    "    else:\n",
    "        linestyle= 'solid'\n",
    "        ax[1].plot(offset_degrees, errors, linestyle=linestyle, label=feature_name)\n",
    "\n",
    "ax2[-1].legend()\n",
    "ax[0].set_ylim(0.0, 100)\n",
    "ax[1].set_ylim(0.0, 0.002)\n",
    "ax[0].legend()\n",
    "ax[1].legend(loc='upper right')\n",
    "fig2.tight_layout()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lume-epics-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
