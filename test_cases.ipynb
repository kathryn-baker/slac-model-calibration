{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Test Cases\n",
    "Here we define the cases we would expect to see of varying drift in the accelerator, for which we want to test for. \n",
    "\n",
    "* normal - the values vary according to some predefined schedule\n",
    "* sensor accuracy decreases over time, slowly getting noisier (does this happen?)\n",
    "* calibration of sensors gets worse over time, e.g. a magnet requiring more current to get the same influence on the beam\n",
    "* the same feature values no longer give the same output values (because of the influence of some external parameter not captured in the features?)\n",
    "* feature values vary according to some periodic function over a time period\n",
    "* machine 'mode' is different, meaning live distribution of feature values is not within the training distribution\n",
    "\n",
    "In each case, we want to apply the test case to the data and observe how the error in the prediction varies over time.\n",
    "\n",
    "**NOTE** Do we use the model's own prediction as the ground truth?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = json.load(open(\"configs/model_info.json\"))\n",
    "pv_info = json.load(open(\"configs/pv_info.json\"))\n",
    "nn_transform_info = json.load(open(\"configs/normalization.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_sim_to_nn_transformers\n",
    "from transformed_model import KeyedTransformedModel\n",
    "# get transformers for normailzation into NN\n",
    "nn_input_transformer, nn_output_transformer = create_sim_to_nn_transformers(\n",
    "    \"configs/normalization.json\"\n",
    ")\n",
    "test_min = torch.tensor(model_info[\"train_input_mins\"])\n",
    "test_max = torch.tensor(model_info[\"train_input_maxs\"]).unsqueeze(0)\n",
    "\n",
    "model = torch.load(\"torch_model.pt\").double()\n",
    "\n",
    "# define the NN surrogate that contains the NN, the input/output transformers for\n",
    "# simulation units\n",
    "surrogate = KeyedTransformedModel(\n",
    "    model,\n",
    "    nn_input_transformer,\n",
    "    nn_output_transformer,\n",
    "    model_info[\"model_in_list\"],\n",
    "    model_info[\"model_out_list\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x_data = np.load(\"data/x_raw_small.npy\", allow_pickle=True)\n",
    "raw_y_data = np.load(\"data/y_raw_small.npy\", allow_pickle=True).astype('float')\n",
    "\n",
    "x_df = pd.DataFrame(raw_x_data, columns=model_info['model_in_list'])\n",
    "y_df = pd.DataFrame(raw_y_data, columns=model_info['model_out_list'])\n",
    "\n",
    "preds = surrogate(torch.tensor(raw_x_data).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal / Noisy Case\n",
    "Here, we keep the parameters constant for a given period of time, including noise on the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 1000\n",
    "nominals = raw_x_data.mean(axis=0)\n",
    "perfect = np.tile(nominals, (n_timesteps,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(data, data2=None, max_time=n_timesteps):\n",
    "    if data.shape[1] != 16:\n",
    "        data = data.T\n",
    "\n",
    "    fig, ax = plt.subplots(4,4, figsize=(20,10))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for idx, (feature_name, min_val, max_val) in enumerate(zip(model_info['model_in_list'], model_info['train_input_mins'], model_info['train_input_maxs'])):\n",
    "        ax[idx].plot(data[:,idx], label=feature_name)\n",
    "        ax[idx].hlines(min_val,xmin=0, xmax=max_time, color='k', linestyle='dashed')\n",
    "        ax[idx].hlines(max_val,xmin=0, xmax=max_time, color='k', linestyle='dashed')\n",
    "        if data2 is not None:\n",
    "            ax[idx].plot(data2[:,idx])\n",
    "        ax[idx].set_title(feature_name)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info['train_input_maxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "noise = np.random.normal(0, (raw_x_data.std(axis=0)+1e-4)*0.1, size=(n_timesteps,16))\n",
    "noisy_data = perfect + noise\n",
    "plot_features(noisy_data, perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(perfect, prediction):\n",
    "    mse = (perfect - prediction)**2\n",
    "    if torch.is_tensor(mse):\n",
    "        return mse.numpy()\n",
    "    else:\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_prediction = surrogate(torch.tensor(perfect).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(data, mse_error, data2=perfect_prediction):\n",
    "    fig, ax = plt.subplots(3,2, figsize=(20,10))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for idx, output_name in enumerate(model_info['model_out_list']):\n",
    "        pred_error = mse_error[:,idx].mean()\n",
    "        ax[idx].plot(data2[:,idx], label='true')\n",
    "        ax[idx].plot(data[:,idx], label='predicted')\n",
    "        ax[idx].set_title(f'{output_name}: {pred_error:.6f}')\n",
    "    \n",
    "    ax[-1].plot(mse_error.mean(axis=1))\n",
    "    ax[-1].set_title('MSE over time')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each 'timestep', use the model to make a prediction and compare it to the ground truth\n",
    "# first we look at the perfect system\n",
    "errors = error(perfect_prediction, perfect_prediction)\n",
    "plot_output(perfect_prediction, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we look at the noisy results to see how they compare\n",
    "noisy_prediction = surrogate(torch.tensor(noisy_data).double())\n",
    "noisy_error = error(perfect_prediction, noisy_prediction)\n",
    "plot_output(noisy_prediction, noisy_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now if we add a small shift to each of the input features as well as the noise\n",
    "shifts = []\n",
    "shift_scale = 0.001\n",
    "for idx, name in enumerate(model_info['model_in_list']):\n",
    "    if name.endswith('gradient'):\n",
    "        # print(name)\n",
    "        shift = shift_scale * nominals[idx]\n",
    "    else:\n",
    "        shift = 0\n",
    "    shifts.append(shift)\n",
    "# shifts = np.array([0.001*nominals[idx] if name.endswith('gradient') else 0 for idx, name in enumerate(model_info['model_in_list'])])\n",
    "fig, ax = plt.subplots(1,2, figsize=(6,3))\n",
    "drift = np.tile(shifts, (n_timesteps,1))\n",
    "ax[0].plot(drift)\n",
    "ax[0].set_title('drift constants')\n",
    "\n",
    "drift = np.cumsum(drift,axis=0)\n",
    "ax[1].plot(drift)\n",
    "ax[1].set_title('cumulative effect of drift')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifting_data = noisy_data + drift\n",
    "plot_features(drifting_data, perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we look at the perfect system\n",
    "drifting_prediction = surrogate(torch.tensor(drifting_data).double())\n",
    "drifting_error = error(perfect_prediction, drifting_prediction)\n",
    "plot_output(drifting_prediction, drifting_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
