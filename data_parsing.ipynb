{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41605057-088a-492e-bb0e-1623ce5343e3",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc82389-ff3c-4466-8635-024569bf97c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca041b87-dd38-491e-a7af-e3bf37fb10fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "filenames = glob.glob('data/machine/**/*.npy', recursive=True)\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70c091-0f46-4e28-a2bb-42c0e66c3b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "char = deepcopy(filenames[0][-7])\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828e36e-fc4f-4d1b-bb2e-487396ac3e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace the filenames if they've got a weird character in (only on linux)\n",
    "char = filenames[0][-7]\n",
    "new_filenames = []\n",
    "for filename in glob.glob('data/machine/missing/*.npy'):\n",
    "    if char != ':':\n",
    "        new_filename = filename.replace(char, ':')\n",
    "        os.rename(filename, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ee247-8872-41b5-bc5e-bc08b6fb1d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we use a set to find the timestamps to remove any duplicate timestamps we have\n",
    "timestamps = set([filename[-29:-4] for filename in glob.glob('data/machine/**/*.npy', recursive=True)])\n",
    "len(timestamps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3c56198-c00a-491a-b2a5-fb93da90a189",
   "metadata": {},
   "source": [
    "For each timestamp, we need to read both the input (`values_*`) file and the output (`img_*`) file and load it into a dataframe, setting the timestamp as the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d848316-184c-4d7a-8730-274871ecf19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series = []\n",
    "input_errors = []\n",
    "output_errors = []\n",
    "\n",
    "for timestamp in timestamps:\n",
    "    data = {'timestamp': timestamp}\n",
    "    try:\n",
    "        input_data = dict(enumerate(np.load(f'data/machine/values_{timestamp}.npy', allow_pickle=True).flatten()))[0]\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            input_data = dict(enumerate(np.load(f'data/machine/missing/values_{timestamp}.npy', allow_pickle=True).flatten()))[0]\n",
    "        except FileNotFoundError:\n",
    "            input_data = {}\n",
    "            input_errors.append(timestamp)\n",
    "    try:\n",
    "        output_data = dict(enumerate(np.load(f'data/machine/imgs_{timestamp}.npy', allow_pickle=True).flatten()))[0]\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            output_data = dict(enumerate(np.load(f'data/machine/missing/imgs_{timestamp}.npy', allow_pickle=True).flatten()))[0]\n",
    "        except FileNotFoundError:\n",
    "            output_data = {}\n",
    "            output_errors.append(timestamp)\n",
    "    data.update(input_data)\n",
    "    data.update(output_data)\n",
    "    time_series.append(data)\n",
    "    \n",
    "    \n",
    "time_series = pd.DataFrame(time_series)\n",
    "time_series['timestamp'] = pd.to_datetime(time_series['timestamp'])\n",
    "# time_series = time_series.set_index('timestamp')\n",
    "print(time_series[['timestamp', 'SOLN:IN20:121:BACT', 'QUAD:IN20:121:BACT']].head())\n",
    "time_series = time_series.sort_values('timestamp').reset_index()\n",
    "print(time_series[['timestamp', 'SOLN:IN20:121:BACT', 'QUAD:IN20:121:BACT']].head())\n",
    "time_series = time_series.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d79fc-f7be-4db7-a496-8f7625a617a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(output_errors))\n",
    "print(len(input_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263ffce-336a-4f7d-bd25-2765018b42dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b49576-647b-477a-9191-b35e496a0588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986b0bc-1c65-41e6-8766-65d45807dc99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad383cd-de69-4e74-9efe-fa1c03a1e341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the full time series\n",
    "start_time = str(time_series['timestamp'].iloc[0]).replace(' ', '_')\n",
    "end_time = str(time_series['timestamp'].iloc[-1]).replace(' ', '_')\n",
    "time_series.to_pickle(f'data/full_{start_time}__{end_time}.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb94a7cb-2a0e-4c1e-81ac-61cd1343a927",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "Now that we have our data loaded, we need to take the subset of the data that we use with our model. Some of the names in the PV info file are wrong (?) so we replace the names with the correct ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7392074-d06f-4f33-9914-fa5936138c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('configs/pv_info.json', 'r') as f:\n",
    "    pv_info = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "input_pvs = [pv_name.replace('BDES', 'BCTRL') for pv_name in pv_info['pv_name_to_sim_name'].keys() if pv_name.replace('BDES', 'BCTRL') in time_series.columns]\n",
    "output_pvs = ['OTRS:IN20:621:XRMS','OTRS:IN20:621:YRMS']\n",
    "time_series_subset = time_series[['timestamp'] + input_pvs + output_pvs]\n",
    "time_series_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c531da1-9d33-4776-8208-852fea0f0b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26014991-4cd8-4c84-921e-27f4688cf5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series_subset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7d6c3-50be-4b1a-8c75-2508eeebe94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "axes = ['magnets', 'outputs', 'others']\n",
    "\n",
    "def plot_series(time_series_subset):\n",
    "\n",
    "    fig, ax = plt.subplots(len(axes),figsize=(15,10))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for col_no, col in enumerate(time_series_subset.columns[1:]):\n",
    "        if 'QUAD' in col or 'SOLN' in col:\n",
    "            ax[0].plot(time_series_subset['timestamp'], time_series_subset[col], '.-',markersize=5, label=col)\n",
    "        elif 'OTRS' in col:\n",
    "            ax[2].plot(time_series_subset['timestamp'], time_series_subset[col], '.-',markersize=5, label=col)\n",
    "        else:\n",
    "            ax[1].plot(time_series_subset['timestamp'], time_series_subset[col], '.-',markersize=5, label=col)\n",
    "        # ax[i].set_ylabel(col)\n",
    "\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[2].legend()\n",
    "    \n",
    "    start_time = str(time_series_subset['timestamp'].iloc[0])\n",
    "    end_time = str(time_series_subset['timestamp'].iloc[-1])\n",
    "    fig.suptitle(f'{start_time[:-6]} -- {end_time[:-6]}')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_series(time_series_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4e328-a257-4d18-ab69-d990bbc1c885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series_subset.to_pickle(f'data/relevant_{start_time}__{end_time}.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec8b2cc0-46bf-4c3e-b753-73807a956ed9",
   "metadata": {},
   "source": [
    "## Create Time Chunks\n",
    "We can see here that there are some gaps in the data where different runs were executed. In order to visualise these better we want to break up the larger dataframe into smaller 'shunks' of each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84bb0d0-10f1-4050-b700-531ff3f99467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_dataset(time_series_subset, time_gap='20 minutes'):\n",
    "    gaps = time_series_subset['timestamp'].diff() > pd.to_timedelta(time_gap)\n",
    "    chunk_indices = np.where(gaps == True)[0]\n",
    "\n",
    "    dfs = []\n",
    "    start_index = 0\n",
    "    for chunk_idx in chunk_indices:\n",
    "        print(start_index, chunk_idx)\n",
    "        df = time_series_subset[start_index:chunk_idx]\n",
    "        dfs.append(df)\n",
    "        start_index = chunk_idx\n",
    "\n",
    "    # then add the last one with the last chunk of data\n",
    "    dfs.append(time_series_subset[start_index:])\n",
    "    print(f'Found {len(dfs)} dataframes')\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506c026-5d17-4237-bbe7-8b84ff150223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = chunk_dataset(time_series_subset, time_gap='20 minutes')\n",
    "# do a final check to make sure the length of all the chunks add up to the total number of points\n",
    "np.sum(np.array([len(df) for df in dfs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e42e2-5b2b-45b6-abb9-8415e8b06bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfab02-5f90-4541-8406-f60cad452f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs[0].tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e8f16-897e-4160-9e1c-0d3af524d5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs[1].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390b5d2-cb62-4af3-87ee-c22146964505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, df in enumerate(dfs):\n",
    "    plot_series(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45aa2e-d798-4fb2-9d7d-93ed27d0f844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# finally, save each of the dataframes to be loaded later\n",
    "for df in dfs:\n",
    "    start_time = str(df['timestamp'].iloc[0]).replace(' ', '_')\n",
    "    end_time = str(df['timestamp'].iloc[-1]).replace(' ', '_')\n",
    "    # filename = f'{start_time}__{end_time}'\n",
    "    df.to_pickle(f'data/{start_time}__{end_time}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
